---
title: "Lab 05 - Permutational ANOVA"
date: 2021/10/13 - 2021/10/15
author: "Nonparametric statistics ay 2021/2022"
output:
  
  html_document: 
    df_print: paged
  pdf_document: default
  html_notebook: 
    df_print: paged
  word_document: default
editor_options: 
  chunk_output_type: inline
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
library(rgl)
knitr::opts_chunk$set(echo = TRUE)
knitr::knit_hooks$set(webgl = hook_webgl)
```

```{css, echo=FALSE}
.extracode {
background-color: lightblue;
}
```

*Disclaimer: The present material has been slightly adapted from the original R
script prepared by me for the a.y. 2020/2021
Nonparametric statistics course. I hereby assume responsibility for any error that may
be present in this document, I do apologise for them and invite you to let me know.*


```{r}

B = 1000
seed = 26111992
```

##Permutational ANOVA
Until now, we have seen how to perform basic statistical tests in a nonparametric and, mainly and more importantly, in a permutational framework.
By going further on this line of thinking, one can perform analysis of variance in a fully permutational (and thus exact...) setting.
The example we will see today is about a fairly old dataset, appeared on Biometrika in 1948 (!!).
It is about am experiment over a number of chickens, fed with different feed types, which were weighted by the experimenter.
You are interested in determining if the feed type has an impact on the chicken weight or not.

Let's import and summarise the dataset


```{r}

chickwts
attach(chickwts)
summary(chickwts)
```
and, let's try to plot the results, to get a bit of info about what's going on...

```{r}
g <- nlevels(feed)
n <- dim(chickwts)[1]


plot(feed, weight, xlab='treat',col=rainbow(g),main='Original Data')
```

The null hypotehsis that we want to test is that, being $\tau_i, i\in \{1,\ldots6\}$ the generic effect of a given level of the treatment. 
$$
H_0: \tau_i=0\;\forall i\;vs\;H_1:\exists\,\tau_i\neq0 
$$

Of course we can solve this in a fully parametric (and admittedly not robust...) way

```{r}
fit <- aov(weight ~ feed)
summary(fit)

```

The strategy that I use to perform permutational ANOVA is to "permutationalise" the F statistic, by computing her permutational distribution under $H_0$.
So...

```{r}
T0 <- summary(fit)[[1]][1,4]
T0

```

To compute the distribution, one simply "scales up" the one used for the 2-sample t-test: I assign at random the treatments (that, under H_0, should all be equal, and equal to 0)

```{r}
T_stat <- numeric(B) 
n <- dim(chickwts)[1]

for(perm in 1:B){
  # Permutation:
  permutation <- sample(1:n)
  weight_perm <- weight[permutation]
  fit_perm <- aov(weight_perm ~ feed)
  
  # Test statistic:
  T_stat[perm] <- summary(fit_perm)[[1]][1,4]
}

```

Let's see the distribution, and then the p-value of the permutational f-test

```{r}
hist(T_stat,xlim=range(c(T_stat,T0)),breaks=30)
abline(v=T0,col=3,lwd=2)

plot(ecdf(T_stat),xlim=c(-1,20))
abline(v=T0,col=3,lwd=4)

# p-value
p_val <- sum(T_stat>=T0)/B
p_val
```

Let's see what happens instead when using lmPerm

```{r}
library(lmPerm)
lmp=aovp(weight_perm ~ feed,perm="Prob",Cp=0.1)#cp is supposed to stop iterations when standard error is at that level...
summary(lmp)
```

let's reduce the expected standard error...

```{r}
lmp=aovp(weight_perm ~ feed,perm="Prob",Cp=1e-6)
summary(lmp)
```

and let's run the instruction several times

```{r}
lmp=aovp(weight_perm ~ feed,perm="Prob",Cp=1e-6)
summary(lmp)

lmp=aovp(weight_perm ~ feed,perm="Prob",Cp=1e-6)
summary(lmp)

lmp=aovp(weight_perm ~ feed,perm="Prob",Cp=1e-6)
summary(lmp)

```

Doesn't really make much sense.


##Multivariate Analysis of Variance

The strategy behind the multivariate analysis of variance is admittedly fairly similar.
We use the Iris dataset

```{r}
data(iris)
attach(iris)
head(iris)
table(iris$Species)
```
let's arrange it a bit, and plot it.

```{r}
species.name <- factor(Species, labels=c('setosa','versicolor','virginica'))
iris4        <- iris[,1:4]
plot(iris4,col=species.name)
```

```{r}
i1 <- which(species.name=='setosa')
i2 <- which(species.name=='versicolor')
i3 <- which(species.name=='virginica')
n1 <- length(i1)
n2 <- length(i2)
n3 <- length(i3)
n  <- n1+n2+n3

g  <- length(levels(species.name))
p  <- 4
```

How to perform a MANOVA test? instead of using the F-test, we will develop a test based on a "permutationalisation" of the Wilks test.
Lets compute the permutational test statistic

```{r}
fit <- manova(as.matrix(iris4) ~ species.name)
summary.manova(fit,test="Wilks") 
T0 <- -summary.manova(fit,test="Wilks")$stats[1,2]
T0


```

And let's now compute instead the permutational distribution of the test statistic.

```{r}
set.seed(seed)
T_stat <- numeric(B)

for(perm in 1:B){
  # choose random permutation
  permutation <- sample(1:n)
  species.name.perm <- species.name[permutation]
  fit.perm <- manova(as.matrix(iris4) ~ species.name.perm)
  T_stat[perm] <- -summary.manova(fit.perm,test="Wilks")$stats[1,2]
}
```

Let's visualise again the distribution, and the p-value

```{r}
hist(T_stat,xlim=range(c(T_stat,T0)),breaks=30)
abline(v=T0,col=3,lwd=2)

plot(ecdf(T_stat),xlim=c(-2,1))
abline(v=T0,col=3,lwd=4)

# p-value
p_val <- sum(T_stat>=T0)/B
p_val


```
Up to now, everything is fairly easy. The situation gets a bit uglier when more than one factor is involved in the model

##Permutational Two-Way ANOVA

In this case we wan to test the efficiency of a car with different fuels, which are classified by their producer or by their octane number
I want to see what are the meaningful factors in determining the number of kms performed with a litre of petrol, interaction included...

This time the data is put in by hand...

```{r}
km          <- c(18.7, 16.8, 20.1, 22.4, 14.0, 15.2, 22.0, 23.3)
station     <- factor(c('Esso','Esso','Esso','Esso','Shell','Shell','Shell','Shell'))
fuel        <- factor(c('95','95','98','98','95','95','98','98'))
station_fuel<- factor(c('Esso95','Esso95','Esso98','Esso98','Shell95','Shell95','Shell98','Shell98'))

M             <- mean(km)
Mstation      <- tapply(km,      station, mean)
Mfuel         <- tapply(km,       fuel, mean)
Mstation_fuel <- tapply(km, station_fuel, mean)
```


Let's also plot the data

```{r}
plot(station_fuel, km, col=rainbow(5)[2:5], ylim=c(0,24))
```


and, of course, I can do everything in a fully parametric setting...


```{r}
# Parametric test:
summary(aov(km ~ station + fuel + station:fuel))
# Without interaction
summary.aov(aov(km ~ station + fuel))
# Without station
summary.aov(aov(km ~ fuel))

```

To do everything in a permutational setting, I need to recognise that, actually, the tests that I need to run are more than one!

The two-way ANOVA model that I want to write is:
$$
Km = \mu + \alpha_i + \beta_j + \gamma_{ij} + \epsilon
$$

So, I need to see if $\gamma=0$, or $\beta=0$ or $alpha=0$ and, for each of this tests, I have a different permutation scheme.

Let's start with the $H_0:\gamma=0$ vs $H_1:\gamma\neq0$.
Under the null hypothesis the model reduces to the additive one: $Km = \mu + \alpha_i + \beta_j + \epsilon$, and permuting the residuals under this model should yield likelihood-invariant datasets.

So, let's compute the test statistic 
```{r}
summary.aov(aov(km ~ station + fuel + station:fuel))
T0_station_fuel <- summary.aov(aov(km ~ station + fuel + station:fuel))[[1]][3,4]
T0_station_fuel

```

and instead compute the permutational distribution:
```{r}

aov.H0station_fuel <- aov(km ~ station + fuel)
aov.H0station_fuel
residuals.H0station_fuel <- aov.H0station_fuel$residuals
n = 8


T_station_fuel <- numeric(B)
for(perm in 1:B){
  permutation <- sample(n)
  residuals.H0station_fuel <- residuals.H0station_fuel[permutation]
  km.perm.H0station_fuel <- aov.H0station_fuel$fitted + residuals.H0station_fuel
  T_station_fuel[perm] <- summary.aov(aov(km.perm.H0station_fuel ~ station + fuel + station:fuel))[[1]][3,4]
}
```
And the p-value...

```{r}
sum(T_station_fuel >= T0_station_fuel)/B
```

Not significant, meaning that I can reduce the model and then perform my test on my main effects.
To test $H_0:\alpha=0$ vs $H_1:\alpha\neq0$, I am assuming under $H_0$ the following model $Km = \mu + \alpha_i + \epsilon$, while for $H_0:\alpha=0$ vs $H_1:\alpha\neq0$ I am assuming $Km = \mu + \beta_j + \epsilon$

Again, the idea is to permute the residuals under $H_0$, so let's compute them

```{r}
T0_station <- summary.aov(aov(km ~ station + fuel))[[1]][1,4]
# residuals under H0:
# km = mu + beta*fuel
aov.H0station <- aov(km ~ fuel)
residuals.H0station <- aov.H0station$residuals

# TEST OF FACTOR FUEL   (H0: beta=0)
T0_fuel <- summary.aov(aov(km ~ station + fuel))[[1]][2,4]
# residuals under H0:
# km = mu + alpha*station
aov.H0fuel <- aov(km ~ station)
residuals.H0fuel <- aov.H0fuel$residuals

```


And let's now compute the permutational distribution, and thus the P-value

```{r}
# TEST OF FACTOR STATION ANF TEST OF FACTOR FUEL
# p-values
B <- 1000
T_fuel <- T_station <- numeric(B)
for(perm in 1:B){
  permutation <- sample(n)
  
  km.perm.H0station <- aov.H0station$fitted + residuals.H0station[permutation]
  T_station[perm] <- summary.aov(aov(km.perm.H0station ~ station + fuel))[[1]][1,4]
  
  km.perm.H0fuel <- aov.H0fuel$fitted + residuals.H0fuel[permutation]
  T_fuel[perm] <- summary.aov(aov(km.perm.H0fuel ~ station + fuel))[[1]][2,4]
}

sum(T_station >= T0_station)/B
sum(T_fuel >= T0_fuel)/B

```

I can remove station, so let's go on on testing Fuel... which actually is a one-way ANOVA...
It can be shown that the residual permutation and the data permutation are the same...



```{r}
# TEST ON THE FACTOR FUEL
T0_fuel <- summary.aov(aov(km ~  fuel))[[1]][1,4]
# residuals under H0
# km = mu
residuals.H0fuel <- km - M

# Note that in this case, permuting the residuals under H0 
# and permuting the data is exactly the same:
permutation <- sample(n)
km.perm.H0fuel <- M + residuals.H0fuel[permutation]
km.perm        <- km[permutation]

km.perm.H0fuel
km.perm
```

```{r}
T_fuel <- numeric(B)
for(perm in 1:B){
  permutation <- sample(n)
  km.perm <- km[permutation]
  T_fuel[perm] <- summary.lm(aov(km.perm ~ fuel ))$f[1]
  
}
sum(T_fuel >= T0_fuel)/B

```

