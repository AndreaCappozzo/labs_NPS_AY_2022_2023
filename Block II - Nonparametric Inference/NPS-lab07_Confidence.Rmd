---
title: "Lab 07 - Permutational Confidence Interval"
date: 2021/10/15
author: "Nonparametric statistics ay 2021/2022"
output:
  
  html_document: 
    df_print: paged
  pdf_document: default
  html_notebook: 
    df_print: paged
  word_document: default
editor_options: 
  chunk_output_type: inline
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
library(rgl)
knitr::opts_chunk$set(echo = TRUE)
knitr::knit_hooks$set(webgl = hook_webgl)
```

```{css, echo=FALSE}
.extracode {
background-color: lightblue;
}
```

*Disclaimer: The present material has been slightly adapted from the original R
script prepared by me for the a.y. 2020/2021
Nonparametric statistics course. I hereby assume responsibility for any error that may
be present in this document, I do apologise for them and invite you to let me know.*


```{r}

seed=2781991
B=1000
```

##Permutational Confidence Intervals
Permutation testing (as the name suggests...) was not really born to make confidence intervals for given parameters, but of course, as shown in class, one can compute exact confidence intervals for given parameters by performing test inversion over a grid of points.

It is relatively computationally intensive, thus we need a bit of "smart" code to do it.
This lab would be indeed more complex from a computational point of view than a statistical one.

Let's simulate some data...

```{r}
set.seed(seed)
data=stabledist::rstable(1000,1.5,0)
hist(data)
median(data)

```

Let's calculate a confidence interval around the median of this distribution, that is...

```{r}
median(data)
```


What we need to do is to test over a fine grid of alternative values that contain our true one the alternative hypothesis $H_1:med(X_1) \neq \mu_0$ where $X_1$ is my distribution.
To do so I use a 1 population test on symmetric distributions, where my permutation scheme is made of reflections of the data

```{r}
uni_t_perm=function(data,mu0,B=1000){

data_trans=data-mu0
T0=abs(median(data_trans))
T_perm=numeric(B)
n=length(data)

for(perm in 1:B){
  
  refl <- rbinom(n, 1, 0.5)*2 - 1
  T_perm[perm]=abs(median(data_trans*refl))

}
return(sum(T_perm>=T0)/B)
}

```


To have a reasonable spatial resolution we need to have a fine grid on which to perform our tests... which means that we need to run A LOT of tests.

```{r}
grid=seq(-3,3,by=0.001)
length(grid)
```

How to do it quickly on R? Vectorise operations instead of using for cycles.
How to do it even faster? Parallelise such vectorised operations!


Let's read the needed packages
```{r}
library(pbapply)
library(parallel)
```

Let's create the cluster and initialise it
I need to start by understanding how many (logical...) cores my machine has
In my case I have...
```{r}
detectCores()
```

So, let's create a cluster with 16 cores!

```{r}

cl=makeCluster(16)

```


I also need to "initialise" my cluster by sending informations that are useful for the computation
```{r}
clusterExport(cl,varlist=list("data","uni_t_perm"))
```

Now, I need to wrap up my function in a "wrapper" with the required arguments, and then start my parallel calculation!


```{r}



perm_wrapper=function(grid_point){uni_t_perm(data,grid_point,B=2000)}
pval_function=pbsapply(grid,perm_wrapper,cl=cl)


```
```{r}
plot(grid,pval_function,type='l')
range(grid[pval_function>0.05])
```

